[{"authors":["admin"],"categories":null,"content":"Hello, thanks for visiting my website.\nI am doing my Bachelor of Actuarial Science at Monash University, majoring in Business Analytics. My goal is to redefine the ways that actuaries work, by incorporating machine learning, computational statistics and data analytics into the traditional types of work that we normally do. Further down the line, I wish to complete a PhD program to gain academic research and teaching experience. My ultimate dream is to become an academic, write textbooks and contribute to the education of future Vietnamese statisticians and data analysts.\nOutside my studies, I love playing the piano, enjoying nature and reading a good book.\n","date":1549324800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1567641600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/nhi-chelsea-le/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/nhi-chelsea-le/","section":"authors","summary":"Hello, thanks for visiting my website.\nI am doing my Bachelor of Actuarial Science at Monash University, majoring in Business Analytics. My goal is to redefine the ways that actuaries work, by incorporating machine learning, computational statistics and data analytics into the traditional types of work that we normally do.","tags":null,"title":"Nhi (Chelsea) Le","type":"authors"},{"authors":[],"categories":[],"content":"\rWhat is Machine Learning (ML)?\rML is not Artificial Intelligence (AI). It is in fact a sub-category of the AI universe. In simple terms, ML is defined as the process of providing the computer (i.e.¬†the machine) with data for it to learn from, so that when presented with new and unseen data in the future, it can correctly predict a desirable response.\nNotice the word ‚Äòpredict‚Äô in bold here. Any ML task can be simply interpreted as a prediction problem.\nE.g. 1. Given all the monthly sales metrics for a particular chips brand over the past 3 years, what is the predicted number of sales for next month?\nE.g.2. Given a handwritten number, what digit is it (from 0 to 9)?\nE.g.3. When an email appears in your inbox, should it be classified as spam, given information such as the addresses you have blocked, advertisement words like promotion or discount, etc.?\nIn statistical terms, ML describes the process below:\nGiven the input information X (also called predictors, (independent) variables, features) and output information Y (also called response or dependent variable), what is the function f that can help us arrive at Y from X, allowing for some random error?\n\\[Y = f(X) + \\epsilon\\]\n\rX variables can be either quantitative or categorical, or a combination of both.\n\rY can be either quantitative or categorical but not both.\n\r\\(\\epsilon\\) is the random, irreducible error that we cannot control nor reduce.\n\r\rThe goal of ML is to estimate unknown function f that can help make use of the predictors X‚Äôs and produce future predictions about the response Y that we are interested in.\nHowever, it is worth noting that no matter how well we try to model this function, it will always contain some error specified by \\(\\epsilon\\) as defined above. So, what is the point of ML then, given that we can never get to the truth?\nConsider the case where \\(\\hat{Y} = \\hat{f}(X)\\) is the predicted value of unknown response Y using the known predictors X and our estimated function f.¬†Let‚Äôs also assume that \\(f(X)\\) and \\(\\hat{f}(X)\\) are known. It follows that (see full derivation at the end of this post):\n\\[E(Y - \\hat{Y}) = E[f(X) + \\epsilon - \\hat{f}(X)]^2 = [f(X) - \\hat{f}(X)]^2 + Var(\\epsilon) \\space \\space \\space \\space \\space \\space \\space \\space (1)\\]\r\\[= Reducible \\space Error + Irreducible \\space Error\\]\rWhere:\n\rReducible error is the squared difference between the actual value of Y, given by \\(f(X)\\) and the predicted value of Y, given by \\(\\hat{f}(X)\\).\n\rIrreducible error is the variance of the error term, \\(Var(\\epsilon)\\).\n\r\rHence, ML aims to estimate function f such that the reducible error is minimised.\n\rParametric and Non-parametric Modeling:\rTo model the function f, we have two options:\nParametric methods:\r\r\rMake assumptions about the form of f (such as: linear, quadratic, piecewise polynomial, etc.).\n\rAdvantage: reduces the problem down to estimating a set of parameters.\n\rDisadvantage: the assumed form of function might be incorrect, resulting in poor performance. This is the problem of high bias (to be discussed shortly).\n\r\rImage credit: ISLR, page 22\nNon-parametric methods:\r\r\rMake NO assumptions about the form of f.¬†Instead, they try to find f that is as close to the data as possible but not perfectly close to avoid overfitting.\n\rAdvantage: highly flexible and can fit a wide range of shapes.\n\rDisadvantage: Unlike parametric methods where the problem is reduced down to estimating only a set of parameters, non-parametric methods require a lot of data to accurately estimate an arbitrary f.¬†Moreover, they are also more easily prone to high variance or overfitting (to be discussed shortly).\n\r\rImage credit: ISLR, page 24\n\rI. Supervised and Unsupervised Learning:\rFull derivation of (1):\n\\[E(Y - \\hat{Y}) = E[f(X) + \\epsilon - \\hat{f}(X)]^2\\]\nWhere \\(f(X)\\) and \\(\\hat{f}(X)\\) are known and \\(\\epsilon\\) is unknown.\rWe have that \\(E(c) = c\\) where \\(c\\) is a constant (i.e.¬†is known).\n\\[E(Y - \\hat{Y}) = E[f(X) + \\epsilon - \\hat{f}(X)]^2 = E[(f(X)-\\hat{f}(X)) + \\epsilon]^2\\]\r\\[= E[f(X)-\\hat{f}(X)]^2 + 2.E[f(X)-\\hat{f}(X)].E(\\epsilon) + E(\\epsilon^2)\\]\rWe also made the assumption that \\(\\epsilon\\) is random, which is equivalent to \\(\\epsilon\\) ~ \\(WN(0, \\sigma_\\epsilon^2)\\). Hence \\(E(\\epsilon)=0\\).\n\\[=E[f(X)-\\hat{f}(X)]^2 + E(\\epsilon^2)\\]\rWe have: $Var() = E(^2) - [E()]^2 = E(^2) $ because \\(E(\\epsilon) = 0\\). And because \\(f(X)\\) and \\(\\hat{f}(X)\\) are known constants:\n\\[= [f(X) - \\hat{f}(X)]^2 + Var(\\epsilon)\\]\n\r","date":1595462400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595496267,"objectID":"f28b42c4feb991d60fe8eb9f3536779e","permalink":"/post/machine-learning-crash-course-p-1-introduction-to-statistical-learning/","publishdate":"2020-07-23T00:00:00Z","relpermalink":"/post/machine-learning-crash-course-p-1-introduction-to-statistical-learning/","section":"post","summary":"What is machine learning? Comparing supervised and unsupervised learning, regression and classification. Introducing the bias-variance tradeoff.","tags":["Machine Learning"],"title":"Machine Learning Crash Course P.1: Introduction to Machine Learning","type":"post"},{"authors":[],"categories":["R"],"content":"Welcome to my Machine Learning Crash Course! In this series, I will attempt to explain fundamental concepts in machine learning to you in understandable terms that are also not oversimplified.\nI am definitely not an expert in the field, just a student who has really enjoyed learning about this area. My coding journey started quite late, only a bit more than half a year ago, when I entered the second semester of my first year at university. So if you are also just starting out, believe that you can and will get better at it, so long as the passion is there.\nThe first post is simply just an overview of what I will be covering throughout the whole crash course. This page has a really nice introduction to machine learning for beginners, which I would definitely recommend you check out first.\nMachine Learning, AI, Deep Learning are oftentimes confused and used interchangeably by some people. Yet they are very different areas of study:\nImage credit: Machine Learning for Everyone\nThe highlighted topics in the image above are those that I will touch on in future posts (since I have not learned about the remaining ones yet). There will also be additional topics to this crash course. You can find the full list below:\n Part 1. Introduction to Statistical Learning\n1.1. Supervised v/s. unsupervised learning\n1.2. Regression v/s. classification\n1.3. Quality of model fit\n1.4. Bias-variance tradeoff\nPart 2. Linear Regression\n2.1. Simple linear regression\n2.2. Multiple linear regression\n2.3. K-nearest neighbours\nPart 3. Classification\n3.1. Logistic regression\n  Simple model (p = 2)\n  Multiple model (p \u0026gt; 2)\n  Multi-class logistic regression\n  3.2. Linear discriminant analysis (LDA)\n  Bayes theorem\n  LDA with p = 1\n  LDA with p \u0026gt;1\n  Quadratic discriminant analysis (QDA)\n  3.3. K-nearest neighbours\n3.4. Comparison of classification models\nPart 4. Resampling\n4.1. Cross-validation (CV)\n  Validation set approach\n  Leave-one-out-cross-validation (LOOCV)\n  k-fold CV\n  Bootstrap\n  Part 5. Regularisation\n5.1. Subset selection\n  Best subset selection\n  Stepwise selection\n  5.2. Shrinkage methods\n  Ridge regression\n  Lasso\n  5.3. Dimension reduction\n  Principal component analysis (PCA)\n  Partial least squares\n  Part 6. Non-linearity\n6.1. Polynomial regression\n6.2. Step functions\n6.3. Basis functions\n6.4. Regression splines\n Piecewise polynomial  6.5. Smoothing splines\n6.6. Local regression\n6.7. Generalised additive models (GAMs)\n  GAMs for regression\n  GAMs for classificaiton\n  Part 7. Tree models\n7.1. Decision trees\n  Regression trees\n  Classification trees\n  7.2. Bagging\n7.3. Boosting\n7.4. Random forests\nPart 8. Support Vector Machines (SVMs)\n8.1. Maximal margin classifier\n8.2. Support vector classfier\n8.3. SVM\n8.4. SVM with more than 2 classes\nPart 9. Unsupervised Learning\n9.1. Clustering methods\n  K-mean clustering\n  Hierarchical clustering\n  9.2. Principal component analysis (PCA)\nCredit I owe the majority of my machine learning knowledge and the inspiration for this course mainly to two sources:\n1. Monash University\u0026rsquo;s ETC3250: Introduction to Machine Learning: unit led by Professor Di Cook:   Course website  Professor Di Cook\u0026rsquo;s website  2. Introduction to Statistical Learning with Applications in R: textbook written by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani:   Link to textbook  Where necessary, I will also credit additional sources of information in my future posts. Thank you for your interest in this Machine Learning Crash Course. I hope you will find it useful in some way.\n","date":1595376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595418586,"objectID":"154a97de8a57a26334115c2edd1694e3","permalink":"/post/machine-learning-crash-course-p-1-overview/","publishdate":"2020-07-22T00:00:00Z","relpermalink":"/post/machine-learning-crash-course-p-1-overview/","section":"post","summary":"Welcome to my Machine Learning Crash Course! In this series, I will attempt to explain fundamental concepts in machine learning to you in understandable terms that are also not oversimplified.","tags":["Machine Learning"],"title":"Machine Learning Crash Course: Overview","type":"post"},{"authors":null,"categories":null,"content":" Predicting hand-drawn sketches from people playing the Pictionary game.  Machine learning models built include: Convolutional Neural Networks (93% accuracy), Random Forests, Extreme Gradient Boosting (XGBoost).  The data can be found here : https://github.com/googlecreativelab/quickdraw-dataset.  ","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588291200,"objectID":"1fa7d302693609ed8b3c11631208a61f","permalink":"/project/image-recognition-project/","publishdate":"2020-05-01T00:00:00Z","relpermalink":"/project/image-recognition-project/","section":"project","summary":"My team's final project for ETC3250 Business at [Monash Business School](https://www.monash.edu/business/home)","tags":["Machine Learning"],"title":"Image Recognition Kaggle Competition","type":"project"},{"authors":null,"categories":null,"content":"The KPMG Data Analytics Virtual Internship Program offered by InsideSherpa has 3 modules:\n Data quality assessment: involves assessment of data quality and completeness in preparation for analysis.  Data insights: involves identifying high-values customers based on customers demographics and attributes. I used R for this task.  Data insights and presentation: producing data visualisations to present key insights and recommendations to the client. I used Tableau for this task.  ","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588291200,"objectID":"ea8399912170bf0a75b3d93dc04d0c72","permalink":"/project/kpmg-vi/","publishdate":"2020-05-01T00:00:00Z","relpermalink":"/project/kpmg-vi/","section":"project","summary":"My deliverables for the KPMG Data Analytics VI at [InsideSherpa](https://www.insidesherpa.com/virtual-internships/theme/m7W4GMqeT3bh9Nb2c/KPMG-Data-Analytics-Virtual-Internship)","tags":["Virtual Internships"],"title":"KPMG Data Analytics Virtual Internship","type":"project"},{"authors":null,"categories":null,"content":"Looking at a classification problem using linear discriminant analysis, quadratic discriminant analysis. Analysing multivariate data analysis using Principle Component Analysis for dimensionality reduction.\n","date":1587772800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587772800,"objectID":"973e38b3d1a44b71492668d98c11df2c","permalink":"/project/principle-component-analysis/","publishdate":"2020-04-25T00:00:00Z","relpermalink":"/project/principle-component-analysis/","section":"project","summary":"My multivariate data analysis using Principle Component Analysis for ETC3250 Business at [Monash Business School](https://www.monash.edu/business/home)","tags":["Machine Learning"],"title":"Principle Component Analysis","type":"project"},{"authors":null,"categories":null,"content":"With everything moving online due to the impact of COVID-19, the Monash Actuarial Students Society (MASS) team decided to come up with brand new initiatives, one of which is the Day in the Life of an Actuary podcast series.\n ‚ÄúDay in the Life of an Actuary‚Äù is a series whereby MASS interview representatives from sponsor firms to discuss the many topics that are of greatest interest to our actuarial student members. This also gives members an insight into what it is like to work as an actuary at the respective firms.\nEpisode 1: Deloitte with Jessica Tran and Jasleen Gill:\nFor this episode, we had the wonderful opportunity to interview Jessica Tran and Jasleen Gill, Graduates and Actuarial Analysts at Deloitte. Together, we were engaged in a very informative, thought-provoking but all the while, interesting conversation about university experiences, internship and graduate applications, the actuarial industry and work of an actuary.\nEpisode 2: KPMG with Jordan Forrest and Clemence Lau\nIn the second episode of our podcast series, ‚ÄúDay in the Life of an Actuary‚Äù, we sat down with Jordan Forrest and Clemence Lau who are Actuarial Consultants at KPMG Australia. Together, we touched on multiple facets of their professional career, ranging from their experiences at university, internship and graduate applications to the actuarial industry and the work of an actuarial consultant at KPMG.\nEpisode 3: UniSuper with Young Tan and Vivian Dang\nIn our third episode of our ‚ÄúDay in the Life of an Actuary‚Äù, we dived into the world of superannuation with Young Tan and Vivian Dang from UniSuper. With a more industry focussed episode, we discussed the projects and unique challenges of working in the superannuation industry and the role of an actuary in this field.\nIt was such a rewarding feeling to receive positive feedback from the students, sponsors and academic staff about our podcast series. This project proved to me that while we cannot control the current situation, we can choose to take initiative and make the best out of the matter at hand.\n","date":1580515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580515200,"objectID":"78bf4771e1a66b6bd9e750d807735e13","permalink":"/project/mass-podcast/","publishdate":"2020-02-01T00:00:00Z","relpermalink":"/project/mass-podcast/","section":"project","summary":"Day in the Life of an Actuary Podcast Series, [Monash Actuarial Students Society](https://www.monashactuary.com.au/)","tags":["Extracurriculars"],"title":"MASS Day in the Life of an Actuary Podcast Series","type":"project"},{"authors":null,"categories":null,"content":"With the impact of COVID-19, Monash University announced several significant cuts in its financial expenses, one of which is funding for clubs and societies on campus.\nMonash University International Students\u0026rsquo; Society (MUISS) has long been fully dependent on the university\u0026rsquo;s central fund for all our activities throughout the year. Therefore, it was undoubtedly challenging for us to continue serving the international students cohort at Monash with such a low budget.\nAs the Treasurer for MUISS, I saw it as my responsibility to make sure that we become more financially independent, not only in 2020 but also in the years to come. Using the experience I have gained working with sponsors over at the Monash Actuarial Students Society (MASS), I initiated a sponsorship project to find external organisations that would be interested in a sponsorship agreement with MUISS.\nThe outcome of the project is still to be finalised, but I have started to receive expressions of interest from some of the organisations that I contacted. It would be so rewarding to leave MUISS at the end of this year with some kind of legacy for future committees.\n","date":1580515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580515200,"objectID":"6dcd0bbf52c902a1c286dcf348f0ad75","permalink":"/project/muiss-sponsorship/","publishdate":"2020-02-01T00:00:00Z","relpermalink":"/project/muiss-sponsorship/","section":"project","summary":"A sponsorship project I do as the Treasurer for the [Monash University International Students' Service](https://www.facebook.com/MUISS.Monash/?ref=page_internal)","tags":["Extracurriculars"],"title":"MUISS Sponsorship Project","type":"project"},{"authors":null,"categories":null,"content":"Earlier this year, I was invited to be a program tester for an exiciting data analytics virtual internship soon to be launched on InsideSherpa. To my complete surprise, this program is from Quantium - a renowned data science company recognised in Australia and globally. Ever since I started my first year at Monash, I have always had an immense passion for data analytics, and so naturally, being able to work at Quantium some day has been my biggest dream.\nThis experience, therefore, was so rewarding and eye-opening for me. Not only was I among the first few people to experience the program prior to its launch day, I was also given the opportunity to provide suggestions on where and how the internship can be further improved. Many of my recommendations ended up being implemented by the InsideSherpa and Quantium teams, which is probably one of the proudest moments of my university years so far.\nThe program gave me invaluable insights on the type of work that an analyst does at Quantium. In particular, I was able to learn so much from how they tackle big and untidy datasets to produce commercial recommendations to the client. I hope to continue sharpening my data analytics and coding skills to hopefully, someday, be able to work at Quantium.\nThe materials (slides, videos) attached to this post are my attempts at the internship only. I will try and set aside some time to walk you through the suggested answers by Quantium as well, so make sure to keep an eye out for that if you are interested!\n","date":1580515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580515200,"objectID":"1692378b7a7a464381479d341d4c06d1","permalink":"/project/quantium-vi/","publishdate":"2020-02-01T00:00:00Z","relpermalink":"/project/quantium-vi/","section":"project","summary":"My deliverables as a program tester for the Quantium Data Analytics VI at [InsideSherpa](https://www.insidesherpa.com/virtual-internships/prototype/NkaC7knWtjSbi6aYv/Data%20Analytics%20Virtual%20Experience%20Program)","tags":["Virtual Internships"],"title":"Quantium Data Analytics Virtual Internship","type":"project"},{"authors":null,"categories":null,"content":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you\u0026rsquo;ll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.toml file.\n```python import pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head() ```  renders as\nimport pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head()  Math Academic supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.toml file.\nTo render inline or block math, wrap your LaTeX math with $...$ or $$...$$, respectively.\nExample math block:\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |} {\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$  renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left |\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right |^2}$$\nExample inline math $\\nabla F(\\mathbf{x}_{n})$ renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the \\\\ math linebreak:\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\ 1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$  renders as\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\n1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$\nDiagrams Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ```  renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2]  An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ```  renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good!  An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ```  renders as\ngantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d  An example class diagram:\n```mermaid classDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() } ```  renders as\nclassDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() }  An example state diagram:\n```mermaid stateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*] ```  renders as\nstateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*]  Todo lists You can even write your todo lists in Academic too:\n- [x] Write math example - [x] Write diagram example - [ ] Do something else  renders as\n Write math example Write diagram example Do something else  Tables Represent your data in tables:\n| First Header | Second Header | | ------------- | ------------- | | Content Cell | Content Cell | | Content Cell | Content Cell |  renders as\n   First Header Second Header     Content Cell Content Cell   Content Cell Content Cell    Asides Academic supports a shortcode for asides, also referred to as notices, hints, or alerts. By wrapping a paragraph in {{% alert note %}} ... {{% /alert %}}, it will render as an aside.\n{{% alert note %}} A Markdown aside is useful for displaying notices, hints, or definitions to your readers. {{% /alert %}}  renders as\n A Markdown aside is useful for displaying notices, hints, or definitions to your readers.   Icons Academic enables you to use a wide range of icons from Font Awesome and Academicons in addition to emojis.\nHere are some examples using the icon shortcode to render icons:\n{{\u0026lt; icon name=\u0026quot;terminal\u0026quot; pack=\u0026quot;fas\u0026quot; \u0026gt;}} Terminal {{\u0026lt; icon name=\u0026quot;python\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} Python {{\u0026lt; icon name=\u0026quot;r-project\u0026quot; pack=\u0026quot;fab\u0026quot; \u0026gt;}} R  renders as\n  Terminal\n Python\n R\nDid you find this page helpful? Consider sharing it üôå ","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Academic","type":"post"},{"authors":["Nhi (Chelsea) Le"],"categories":[],"content":"from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')  print(\u0026quot;Welcome to Academic!\u0026quot;)  Welcome to Academic!  Install Python and JupyterLab  Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb  The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata ( front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post's title date: 2019-09-01 # Put any other Academic metadata here... ---  Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.  Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":["R"],"content":"\rR Markdown\rThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com.\nYou can embed an R code chunk like this:\nsummary(cars)\r## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00\rfit \u0026lt;- lm(dist ~ speed, data = cars)\rfit\r## ## Call:\r## lm(formula = dist ~ speed, data = cars)\r## ## Coefficients:\r## (Intercept) speed ## -17.579 3.932\r\rIncluding Plots\rYou can also embed plots. See Figure 1 for example:\npar(mar = c(0, 1, 0, 1))\rpie(\rc(280, 60, 20),\rc(\u0026#39;Sky\u0026#39;, \u0026#39;Sunny side of pyramid\u0026#39;, \u0026#39;Shady side of pyramid\u0026#39;),\rcol = c(\u0026#39;#0292D8\u0026#39;, \u0026#39;#F7EA39\u0026#39;, \u0026#39;#C4B632\u0026#39;),\rinit.angle = -50, border = NA\r)\r\rFigure 1: A fancy pie chart.\r\r\r","date":1437703994,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437703994,"objectID":"10065deaa3098b0da91b78b48d0efc71","permalink":"/post/2015-07-23-r-rmarkdown/","publishdate":"2015-07-23T21:13:14-05:00","relpermalink":"/post/2015-07-23-r-rmarkdown/","section":"post","summary":"R Markdown\rThis is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.","tags":["R Markdown","plot","regression"],"title":"Hello R Markdown","type":"post"}]