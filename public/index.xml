<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nhi (Chelsea) Le</title>
    <link>/</link>
      <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <description>Nhi (Chelsea) Le</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 28 Jun 2018 00:00:00 +0100</lastBuildDate>
    <image>
      <url>/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Nhi (Chelsea) Le</title>
      <link>/</link>
    </image>
    
    <item>
      <title>Machine Learning Crash Course P.1: Introduction to Machine Learning</title>
      <link>/post/machine-learning-crash-course-p-1-introduction-to-statistical-learning/</link>
      <pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate>
      <guid>/post/machine-learning-crash-course-p-1-introduction-to-statistical-learning/</guid>
      <description>


&lt;div id=&#34;what-is-machine-learning-ml&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;strong&gt;What is Machine Learning (ML)?&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;ML is not Artificial Intelligence (AI). It is in fact a sub-category of the AI universe. &lt;span style=&#34;color:green&#34;&gt;In simple terms, ML is defined as the process of providing the computer (i.e.¬†the machine) with data for it to learn from, so that when presented with new and unseen data in the future, it can correctly &lt;strong&gt;predict&lt;/strong&gt; a desirable response.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Notice the word ‚Äòpredict‚Äô in bold here. &lt;strong&gt;Any ML task can be simply interpreted as a prediction problem&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;E.g. 1. Given all the monthly sales metrics for a particular chips brand over the past 3 years, what is the predicted number of sales for next month?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;E.g.2. Given a handwritten number, what digit is it (from 0 to 9)?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;E.g.3. When an email appears in your inbox, should it be classified as spam, given information such as the addresses you have blocked, advertisement words like promotion or discount, etc.?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:green&#34;&gt;In statistical terms, ML describes the process below:&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Given the &lt;strong&gt;input information X&lt;/strong&gt; (also called predictors, (independent) variables, features) and &lt;strong&gt;output information Y&lt;/strong&gt; (also called response or dependent variable), what is the function f that can help us arrive at Y from X, allowing for some random error?&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = f(X) + \epsilon\]&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;X variables can be either quantitative or categorical, or a combination of both.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Y can be either quantitative or categorical but not both.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is the random, irreducible error that we cannot control nor reduce.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The goal of ML is to estimate unknown function f that can help make use of the predictors X‚Äôs and produce future predictions about the response Y that we are interested in.&lt;/p&gt;
&lt;p&gt;However, it is worth noting that no matter how well we try to model this function, it will always contain some error specified by &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; as defined above. So, what is the point of ML then, given that we can never get to the truth?&lt;/p&gt;
&lt;p&gt;Consider the case where &lt;span class=&#34;math inline&#34;&gt;\(\hat{Y} = \hat{f}(X)\)&lt;/span&gt; is the predicted value of unknown response Y using the known predictors X and our estimated function f.¬†Let‚Äôs also assume that &lt;span class=&#34;math inline&#34;&gt;\(f(X)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\hat{f}(X)\)&lt;/span&gt; are known. It follows that (see full derivation at the end of this post):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E(Y - \hat{Y}) = E[f(X) + \epsilon - \hat{f}(X)]^2 = [f(X) - \hat{f}(X)]^2 + Var(\epsilon) \space \space \space \space \space \space \space \space (1)\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[= Reducible \space Error + Irreducible \space Error\]&lt;/span&gt;
Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Reducible error is the squared difference between the actual value of Y, given by &lt;span class=&#34;math inline&#34;&gt;\(f(X)\)&lt;/span&gt; and the predicted value of Y, given by &lt;span class=&#34;math inline&#34;&gt;\(\hat{f}(X)\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Irreducible error is the variance of the error term, &lt;span class=&#34;math inline&#34;&gt;\(Var(\epsilon)\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hence, &lt;span style=&#34;color:green&#34;&gt;&lt;strong&gt;ML aims to estimate function f such that the reducible error is minimised.&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parametric-and-non-parametric-modeling&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;strong&gt;Parametric and Non-parametric Modeling:&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;To model the function f, we have two options:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Parametric methods:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Make assumptions about the form of f (such as: linear, quadratic, piecewise polynomial, etc.).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Advantage: reduces the problem down to estimating a set of parameters.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Disadvantage: the assumed form of function might be incorrect, resulting in poor performance. This is the problem of &lt;strong&gt;high bias&lt;/strong&gt; (to be discussed shortly).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;parametric.png&#34; alt=&#34;png&#34; /&gt;
&lt;em&gt;Image credit: &lt;a href=&#34;http://faculty.marshall.usc.edu/gareth-james/ISL/&#34;&gt;ISLR&lt;/a&gt;, page 22&lt;/em&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Non-parametric methods:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Make NO assumptions about the form of f.¬†Instead, they try to find f that is as close to the data as possible but not perfectly close to avoid &lt;strong&gt;overfitting&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Advantage: highly flexible and can fit a wide range of shapes.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Disadvantage: Unlike parametric methods where the problem is reduced down to estimating only a set of parameters, non-parametric methods require a lot of data to accurately estimate an arbitrary f.¬†Moreover, they are also more easily prone to &lt;strong&gt;high variance&lt;/strong&gt; or &lt;strong&gt;overfitting&lt;/strong&gt; (to be discussed shortly).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;nonparametric.png&#34; alt=&#34;png&#34; /&gt;
&lt;em&gt;Image credit: &lt;a href=&#34;http://faculty.marshall.usc.edu/gareth-james/ISL/&#34;&gt;ISLR&lt;/a&gt;, page 24&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;i.-supervised-and-unsupervised-learning&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;strong&gt;I. Supervised and Unsupervised Learning:&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Full derivation of (1):&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E(Y - \hat{Y}) = E[f(X) + \epsilon - \hat{f}(X)]^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Where &lt;span class=&#34;math inline&#34;&gt;\(f(X)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\hat{f}(X)\)&lt;/span&gt; are known and &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is unknown.
We have that &lt;span class=&#34;math inline&#34;&gt;\(E(c) = c\)&lt;/span&gt; where &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is a constant (i.e.¬†is known).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[E(Y - \hat{Y}) = E[f(X) + \epsilon - \hat{f}(X)]^2 = E[(f(X)-\hat{f}(X)) + \epsilon]^2\]&lt;/span&gt;
&lt;span class=&#34;math display&#34;&gt;\[= E[f(X)-\hat{f}(X)]^2 + 2.E[f(X)-\hat{f}(X)].E(\epsilon) + E(\epsilon^2)\]&lt;/span&gt;
&lt;em&gt;We also made the assumption that &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; is random, which is equivalent to &lt;span class=&#34;math inline&#34;&gt;\(\epsilon\)&lt;/span&gt; ~ &lt;span class=&#34;math inline&#34;&gt;\(WN(0, \sigma_\epsilon^2)\)&lt;/span&gt;. Hence &lt;span class=&#34;math inline&#34;&gt;\(E(\epsilon)=0\)&lt;/span&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[=E[f(X)-\hat{f}(X)]^2 + E(\epsilon^2)\]&lt;/span&gt;
&lt;em&gt;We have: $Var() = E(^2) - [E()]^2 = E(^2) $ because &lt;span class=&#34;math inline&#34;&gt;\(E(\epsilon) = 0\)&lt;/span&gt;. And because &lt;span class=&#34;math inline&#34;&gt;\(f(X)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\hat{f}(X)\)&lt;/span&gt; are known constants:&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[= [f(X) - \hat{f}(X)]^2 + Var(\epsilon)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Machine Learning Crash Course: Overview</title>
      <link>/post/machine-learning-crash-course-p-1-overview/</link>
      <pubDate>Wed, 22 Jul 2020 00:00:00 +0000</pubDate>
      <guid>/post/machine-learning-crash-course-p-1-overview/</guid>
      <description>&lt;h2 id=&#34;welcome-to-my-machine-learning-crash-course&#34;&gt;&lt;strong&gt;Welcome to my Machine Learning Crash Course!&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;In this series, I will attempt to explain fundamental concepts in machine learning to you in understandable terms that are also not oversimplified.&lt;/p&gt;
&lt;p&gt;I am definitely not an expert in the field, just a student who has really enjoyed learning about this area. My coding journey started quite late, only a bit more than half a year ago, when I entered the second semester of my first year at university. So if you are also just starting out, believe that you can and will get better at it, so long as the passion is there.&lt;/p&gt;
&lt;p&gt;The first post is simply just an overview of what I will be covering throughout the whole crash course. 
&lt;a href=&#34;https://vas3k.com/blog/machine_learning/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;This page&lt;/a&gt; has a really nice introduction to machine learning for beginners, which I would definitely recommend you check out first.&lt;/p&gt;
&lt;p&gt;Machine Learning, AI, Deep Learning are oftentimes confused and used interchangeably by some people. Yet they are very different areas of study:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/ml-1/index_files/ml-1-overview.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-07-22-trial-2_files/ml-1-overview.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Image credit: 
&lt;a href=&#34;https://vas3k.com/blog/machine_learning/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Machine Learning for Everyone&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The highlighted topics in the image above are those that I will touch on in future posts (since I have not learned about the remaining ones yet). There will also be additional topics to this crash course. You can find the full list below:&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://nhi-chelsea-le.netlify.app/post/machine-learning-crash-course-p-1-introduction-to-statistical-learning/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Part 1. Introduction to Statistical Learning&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;1.1. Supervised v/s. unsupervised learning&lt;/p&gt;
&lt;p&gt;1.2. Regression v/s. classification&lt;/p&gt;
&lt;p&gt;1.3. Quality of model fit&lt;/p&gt;
&lt;p&gt;1.4. Bias-variance tradeoff&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;strong&gt;Part 2. Linear Regression&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;2.1. Simple linear regression&lt;/p&gt;
&lt;p&gt;2.2. Multiple linear regression&lt;/p&gt;
&lt;p&gt;2.3. K-nearest neighbours&lt;/p&gt;
&lt;br&gt; 
&lt;p&gt;&lt;strong&gt;Part 3. Classification&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;3.1. Logistic regression&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Simple model (p = 2)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Multiple model (p &amp;gt; 2)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Multi-class logistic regression&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;3.2. Linear discriminant analysis (LDA)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Bayes theorem&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LDA with p = 1&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LDA with p &amp;gt;1&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Quadratic discriminant analysis (QDA)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;3.3. K-nearest neighbours&lt;/p&gt;
&lt;p&gt;3.4. Comparison of classification models&lt;/p&gt;
&lt;br&gt; 
&lt;p&gt;&lt;strong&gt;Part 4. Resampling&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;4.1. Cross-validation (CV)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Validation set approach&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Leave-one-out-cross-validation (LOOCV)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k-fold CV&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bootstrap&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt; 
&lt;p&gt;&lt;strong&gt;Part 5. Regularisation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;5.1. Subset selection&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Best subset selection&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Stepwise selection&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;5.2. Shrinkage methods&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Ridge regression&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Lasso&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;5.3. Dimension reduction&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Principal component analysis (PCA)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Partial least squares&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt; 
&lt;p&gt;&lt;strong&gt;Part 6. Non-linearity&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;6.1. Polynomial regression&lt;/p&gt;
&lt;p&gt;6.2. Step functions&lt;/p&gt;
&lt;p&gt;6.3. Basis functions&lt;/p&gt;
&lt;p&gt;6.4. Regression splines&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Piecewise polynomial&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;6.5. Smoothing splines&lt;/p&gt;
&lt;p&gt;6.6. Local regression&lt;/p&gt;
&lt;p&gt;6.7. Generalised additive models (GAMs)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;GAMs for regression&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GAMs for classificaiton&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;br&gt;
&lt;p&gt;&lt;strong&gt;Part 7. Tree models&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;7.1. Decision trees&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Regression trees&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Classification trees&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;7.2. Bagging&lt;/p&gt;
&lt;p&gt;7.3. Boosting&lt;/p&gt;
&lt;p&gt;7.4. Random forests&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;strong&gt;Part 8. Support Vector Machines (SVMs)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;8.1. Maximal margin classifier&lt;/p&gt;
&lt;p&gt;8.2. Support vector classfier&lt;/p&gt;
&lt;p&gt;8.3. SVM&lt;/p&gt;
&lt;p&gt;8.4. SVM with more than 2 classes&lt;/p&gt;
&lt;br&gt; 
&lt;p&gt;&lt;strong&gt;Part 9. Unsupervised Learning&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;9.1. Clustering methods&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;K-mean clustering&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Hierarchical clustering&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;9.2. Principal component analysis (PCA)&lt;/p&gt;
&lt;h2 id=&#34;credit&#34;&gt;&lt;strong&gt;Credit&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;I owe the majority of my machine learning knowledge and the inspiration for this course mainly to two sources:&lt;/p&gt;
&lt;h2 id=&#34;1-monash-universitys-etc3250-introduction-to-machine-learning-unit-led-by-professor-di-cook&#34;&gt;1. Monash University&amp;rsquo;s ETC3250: Introduction to Machine Learning: unit led by Professor Di Cook:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://iml.numbat.space/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Course website&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;http://dicook.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Professor Di Cook&amp;rsquo;s website&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2-introduction-to-statistical-learning-with-applications-in-r-textbook-written-by-gareth-james-daniela-witten-trevor-hastie-and-robert-tibshirani&#34;&gt;2. Introduction to Statistical Learning with Applications in R: textbook written by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;http://faculty.marshall.usc.edu/gareth-james/ISL/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Link to textbook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Where necessary, I will also credit additional sources of information in my future posts. Thank you for your interest in this Machine Learning Crash Course. I hope you will find it useful in some way.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Image Recognition Kaggle Competition</title>
      <link>/project/image-recognition-project/</link>
      <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
      <guid>/project/image-recognition-project/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;Predicting hand-drawn sketches from people playing the Pictionary game.
&lt;br&gt;&lt;/li&gt;
&lt;li&gt;Machine learning models built include: Convolutional Neural Networks (93% accuracy), Random Forests, Extreme Gradient Boosting (XGBoost). 
&lt;br&gt;&lt;/li&gt;
&lt;li&gt;The data can be found here : &lt;a href=&#34;https://github.com/googlecreativelab/quickdraw-dataset&#34;&gt;https://github.com/googlecreativelab/quickdraw-dataset&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>KPMG Data Analytics Virtual Internship</title>
      <link>/project/kpmg-vi/</link>
      <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
      <guid>/project/kpmg-vi/</guid>
      <description>&lt;p&gt;The KPMG Data Analytics Virtual Internship Program offered by InsideSherpa has 3 modules:&lt;/p&gt;
&lt;br&gt; 
&lt;ol&gt;
&lt;li&gt;Data quality assessment: involves assessment of data quality and completeness in preparation for analysis.&lt;/li&gt;
&lt;/ol&gt;
&lt;br&gt; 
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Data insights: involves identifying high-values customers based on customers demographics and attributes. I used R for this task.&lt;/li&gt;
&lt;/ol&gt;
&lt;br&gt; 
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Data insights and presentation: producing data visualisations to present key insights and recommendations to the client. I used Tableau for this task.&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Principle Component Analysis</title>
      <link>/project/principle-component-analysis/</link>
      <pubDate>Sat, 25 Apr 2020 00:00:00 +0000</pubDate>
      <guid>/project/principle-component-analysis/</guid>
      <description>&lt;p&gt;Looking at a classification problem using linear discriminant analysis, quadratic discriminant analysis. Analysing multivariate data analysis using Principle Component Analysis for dimensionality reduction.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MASS Day in the Life of an Actuary Podcast Series</title>
      <link>/project/mass-podcast/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/project/mass-podcast/</guid>
      <description>&lt;p&gt;With everything moving online due to the impact of COVID-19, the Monash Actuarial Students Society (MASS) team decided to come up with brand new initiatives, one of which is the Day in the Life of an Actuary podcast series.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.monashactuary.com.au/podcasts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;‚ÄúDay in the Life of an Actuary‚Äù&lt;/a&gt; is a series whereby MASS interview representatives from sponsor firms to discuss the many topics that are of greatest interest to our actuarial student members. This also gives members an insight into what it is like to work as an actuary at the respective firms.&lt;/p&gt;
&lt;br&gt; 
&lt;p&gt;&lt;strong&gt;Episode 1: Deloitte with Jessica Tran and Jasleen Gill&lt;/strong&gt;:&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;For this episode, we had the wonderful opportunity to interview Jessica Tran and Jasleen Gill, Graduates and Actuarial Analysts at Deloitte. Together, we were engaged in a very informative, thought-provoking but all the while, interesting conversation about university experiences, internship and graduate applications, the actuarial industry and work of an actuary.&lt;/p&gt;
&lt;br&gt;
&lt;p&gt;&lt;strong&gt;Episode 2: KPMG with Jordan Forrest and Clemence Lau&lt;/strong&gt;&lt;/p&gt;
&lt;br&gt; 
&lt;p&gt;In the second episode of our podcast series, ‚ÄúDay in the Life of an Actuary‚Äù, we sat down with Jordan Forrest and Clemence Lau who are Actuarial Consultants at KPMG Australia. Together, we touched on multiple facets of their professional career, ranging from their experiences at university, internship and graduate applications to the actuarial industry and the work of an actuarial consultant at KPMG.&lt;/p&gt;
&lt;br&gt; 
&lt;p&gt;&lt;strong&gt;Episode 3: UniSuper with Young Tan and Vivian Dang&lt;/strong&gt;&lt;/p&gt;
&lt;br&gt; 
&lt;p&gt;In our third episode of our ‚ÄúDay in the Life of an Actuary‚Äù, we dived into the world of superannuation with Young Tan and Vivian Dang from UniSuper. With a more industry focussed episode, we discussed the projects and unique challenges of working in the superannuation industry and the role of an actuary in this field.&lt;/p&gt;
&lt;br&gt; 
&lt;p&gt;It was such a rewarding feeling to receive positive feedback from the students, sponsors and academic staff about our podcast series. This project proved to me that while we cannot control the current situation, we can choose to take initiative and make the best out of the matter at hand.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MUISS Sponsorship Project</title>
      <link>/project/muiss-sponsorship/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/project/muiss-sponsorship/</guid>
      <description>&lt;p&gt;With the impact of COVID-19, Monash University announced several significant cuts in its financial expenses, one of which is funding for clubs and societies on campus.&lt;/p&gt;
&lt;br&gt; 
&lt;p&gt;Monash University International Students&amp;rsquo; Society (MUISS) has long been fully dependent on the university&amp;rsquo;s central fund for all our activities throughout the year. Therefore, it was undoubtedly challenging for us to continue serving the international students cohort at Monash with such a low budget.&lt;/p&gt;
&lt;br&gt; 
&lt;p&gt;As the Treasurer for MUISS, I saw it as my responsibility to make sure that we become more financially independent, not only in 2020 but also in the years to come. Using the experience I have gained working with sponsors over at the Monash Actuarial Students Society (MASS), I initiated a sponsorship project to find external organisations that would be interested in a sponsorship agreement with MUISS.&lt;/p&gt;
&lt;br&gt; 
&lt;p&gt;The outcome of the project is still to be finalised, but I have started to receive expressions of interest from some of the organisations that I contacted. It would be so rewarding to leave MUISS at the end of this year with some kind of legacy for future committees.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Quantium Data Analytics Virtual Internship</title>
      <link>/project/quantium-vi/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 +0000</pubDate>
      <guid>/project/quantium-vi/</guid>
      <description>&lt;p&gt;Earlier this year, I was invited to be a program tester for an exiciting data analytics virtual internship soon to be launched on InsideSherpa. To my complete surprise, this program is from Quantium - a renowned data science company recognised in Australia and globally. Ever since I started my first year at Monash, I have always had an immense passion for data analytics, and so naturally, being able to work at Quantium some day has been my biggest dream.&lt;/p&gt;
&lt;p&gt;This experience, therefore, was so rewarding and eye-opening for me. Not only was I among the first few people to experience the program prior to its launch day, I was also given the opportunity to provide suggestions on where and how the internship can be further improved. Many of my recommendations ended up being implemented by the InsideSherpa and Quantium teams, which is probably one of the proudest moments of my university years so far.&lt;/p&gt;
&lt;p&gt;The program gave me invaluable insights on the type of work that an analyst does at Quantium. In particular, I was able to learn so much from how they tackle big and untidy datasets to produce commercial recommendations to the client. I hope to continue sharpening my data analytics and coding skills to hopefully, someday, be able to work at Quantium.&lt;/p&gt;
&lt;p&gt;The materials (slides, videos) attached to this post are my attempts at the internship only. I will try and set aside some time to walk you through the suggested answers by Quantium as well, so make sure to keep an eye out for that if you are interested!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Writing technical content in Academic</title>
      <link>/post/writing-technical-content/</link>
      <pubDate>Fri, 12 Jul 2019 00:00:00 +0000</pubDate>
      <guid>/post/writing-technical-content/</guid>
      <description>&lt;p&gt;Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Highlight your code snippets, take notes on math classes, and draw diagrams from textual representation.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;On this page, you&amp;rsquo;ll find some examples of the types of technical content that can be rendered with Academic.&lt;/p&gt;
&lt;h2 id=&#34;examples&#34;&gt;Examples&lt;/h2&gt;
&lt;h3 id=&#34;code&#34;&gt;Code&lt;/h3&gt;
&lt;p&gt;Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the &lt;code&gt;highlight&lt;/code&gt; option in your &lt;code&gt;config/_default/params.toml&lt;/code&gt; file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```python
import pandas as pd
data = pd.read_csv(&amp;quot;data.csv&amp;quot;)
data.head()
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas as pd
data = pd.read_csv(&amp;quot;data.csv&amp;quot;)
data.head()
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;math&#34;&gt;Math&lt;/h3&gt;
&lt;p&gt;Academic supports a Markdown extension for $\LaTeX$ math. You can enable this feature by toggling the &lt;code&gt;math&lt;/code&gt; option in your &lt;code&gt;config/_default/params.toml&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;To render &lt;em&gt;inline&lt;/em&gt; or &lt;em&gt;block&lt;/em&gt; math, wrap your LaTeX math with &lt;code&gt;$...$&lt;/code&gt; or &lt;code&gt;$$...$$&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;math block&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-tex&#34;&gt;$$\gamma_{n} = \frac{ 
\left | \left (\mathbf x_{n} - \mathbf x_{n-1} \right )^T 
\left [\nabla F (\mathbf x_{n}) - \nabla F (\mathbf x_{n-1}) \right ] \right |}
{\left \|\nabla F(\mathbf{x}_{n}) - \nabla F(\mathbf{x}_{n-1}) \right \|^2}$$
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;$$\gamma_{n} = \frac{ \left | \left (\mathbf x_{n} - \mathbf x_{n-1} \right )^T \left [\nabla F (\mathbf x_{n}) - \nabla F (\mathbf x_{n-1}) \right ] \right |}{\left |\nabla F(\mathbf{x}_{n}) - \nabla F(\mathbf{x}_{n-1}) \right |^2}$$&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;inline math&lt;/strong&gt; &lt;code&gt;$\nabla F(\mathbf{x}_{n})$&lt;/code&gt; renders as $\nabla F(\mathbf{x}_{n})$.&lt;/p&gt;
&lt;p&gt;Example &lt;strong&gt;multi-line math&lt;/strong&gt; using the &lt;code&gt;\\&lt;/code&gt; math linebreak:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-tex&#34;&gt;$$f(k;p_0^*) = \begin{cases} p_0^* &amp;amp; \text{if }k=1, \\
1-p_0^* &amp;amp; \text {if }k=0.\end{cases}$$
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;$$f(k;p_0^*) = \begin{cases} p_0^* &amp;amp; \text{if }k=1, \&lt;br&gt;
1-p_0^* &amp;amp; \text {if }k=0.\end{cases}$$&lt;/p&gt;
&lt;h3 id=&#34;diagrams&#34;&gt;Diagrams&lt;/h3&gt;
&lt;p&gt;Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the &lt;code&gt;diagram&lt;/code&gt; option in your &lt;code&gt;config/_default/params.toml&lt;/code&gt; file or by adding &lt;code&gt;diagram: true&lt;/code&gt; to your page front matter.&lt;/p&gt;
&lt;p&gt;An example &lt;strong&gt;flowchart&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
graph TD
A[Hard] --&amp;gt;|Text| B(Round)
B --&amp;gt; C{Decision}
C --&amp;gt;|One| D[Result 1]
C --&amp;gt;|Two| E[Result 2]
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD
A[Hard] --&amp;gt;|Text| B(Round)
B --&amp;gt; C{Decision}
C --&amp;gt;|One| D[Result 1]
C --&amp;gt;|Two| E[Result 2]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An example &lt;strong&gt;sequence diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
sequenceDiagram
Alice-&amp;gt;&amp;gt;John: Hello John, how are you?
loop Healthcheck
    John-&amp;gt;&amp;gt;John: Fight against hypochondria
end
Note right of John: Rational thoughts!
John--&amp;gt;&amp;gt;Alice: Great!
John-&amp;gt;&amp;gt;Bob: How about you?
Bob--&amp;gt;&amp;gt;John: Jolly good!
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;sequenceDiagram
Alice-&amp;gt;&amp;gt;John: Hello John, how are you?
loop Healthcheck
    John-&amp;gt;&amp;gt;John: Fight against hypochondria
end
Note right of John: Rational thoughts!
John--&amp;gt;&amp;gt;Alice: Great!
John-&amp;gt;&amp;gt;Bob: How about you?
Bob--&amp;gt;&amp;gt;John: Jolly good!
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An example &lt;strong&gt;Gantt diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
gantt
section Section
Completed :done,    des1, 2014-01-06,2014-01-08
Active        :active,  des2, 2014-01-07, 3d
Parallel 1   :         des3, after des1, 1d
Parallel 2   :         des4, after des1, 1d
Parallel 3   :         des5, after des3, 1d
Parallel 4   :         des6, after des4, 1d
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;gantt
section Section
Completed :done,    des1, 2014-01-06,2014-01-08
Active        :active,  des2, 2014-01-07, 3d
Parallel 1   :         des3, after des1, 1d
Parallel 2   :         des4, after des1, 1d
Parallel 3   :         des5, after des3, 1d
Parallel 4   :         des6, after des4, 1d
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An example &lt;strong&gt;class diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
classDiagram
Class01 &amp;lt;|-- AveryLongClass : Cool
&amp;lt;&amp;lt;interface&amp;gt;&amp;gt; Class01
Class09 --&amp;gt; C2 : Where am i?
Class09 --* C3
Class09 --|&amp;gt; Class07
Class07 : equals()
Class07 : Object[] elementData
Class01 : size()
Class01 : int chimp
Class01 : int gorilla
class Class10 {
  &amp;lt;&amp;lt;service&amp;gt;&amp;gt;
  int id
  size()
}
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;classDiagram
Class01 &amp;lt;|-- AveryLongClass : Cool
&amp;lt;&amp;lt;interface&amp;gt;&amp;gt; Class01
Class09 --&amp;gt; C2 : Where am i?
Class09 --* C3
Class09 --|&amp;gt; Class07
Class07 : equals()
Class07 : Object[] elementData
Class01 : size()
Class01 : int chimp
Class01 : int gorilla
class Class10 {
  &amp;lt;&amp;lt;service&amp;gt;&amp;gt;
  int id
  size()
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An example &lt;strong&gt;state diagram&lt;/strong&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;```mermaid
stateDiagram
[*] --&amp;gt; Still
Still --&amp;gt; [*]
Still --&amp;gt; Moving
Moving --&amp;gt; Still
Moving --&amp;gt; Crash
Crash --&amp;gt; [*]
```
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;stateDiagram
[*] --&amp;gt; Still
Still --&amp;gt; [*]
Still --&amp;gt; Moving
Moving --&amp;gt; Still
Moving --&amp;gt; Crash
Crash --&amp;gt; [*]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;todo-lists&#34;&gt;Todo lists&lt;/h3&gt;
&lt;p&gt;You can even write your todo lists in Academic too:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;- [x] Write math example
- [x] Write diagram example
- [ ] Do something else
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Write math example&lt;/li&gt;
&lt;li&gt;&lt;input checked=&#34;&#34; disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Write diagram example&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; Do something else&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;tables&#34;&gt;Tables&lt;/h3&gt;
&lt;p&gt;Represent your data in tables:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;| First Header  | Second Header |
| ------------- | ------------- |
| Content Cell  | Content Cell  |
| Content Cell  | Content Cell  |
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;First Header&lt;/th&gt;
&lt;th&gt;Second Header&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Content Cell&lt;/td&gt;
&lt;td&gt;Content Cell&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Content Cell&lt;/td&gt;
&lt;td&gt;Content Cell&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;asides&#34;&gt;Asides&lt;/h3&gt;
&lt;p&gt;Academic supports a 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/#alerts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;shortcode for asides&lt;/a&gt;, also referred to as &lt;em&gt;notices&lt;/em&gt;, &lt;em&gt;hints&lt;/em&gt;, or &lt;em&gt;alerts&lt;/em&gt;. By wrapping a paragraph in &lt;code&gt;{{% alert note %}} ... {{% /alert %}}&lt;/code&gt;, it will render as an aside.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% alert note %}}
A Markdown aside is useful for displaying notices, hints, or definitions to your readers.
{{% /alert %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;div&gt;
    A Markdown aside is useful for displaying notices, hints, or definitions to your readers.
  &lt;/div&gt;
&lt;/div&gt;
&lt;h3 id=&#34;icons&#34;&gt;Icons&lt;/h3&gt;
&lt;p&gt;Academic enables you to use a wide range of 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/page-builder/#icons&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;icons from &lt;em&gt;Font Awesome&lt;/em&gt; and &lt;em&gt;Academicons&lt;/em&gt;&lt;/a&gt; in addition to 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/#emojis&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;emojis&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here are some examples using the &lt;code&gt;icon&lt;/code&gt; shortcode to render icons:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; icon name=&amp;quot;terminal&amp;quot; pack=&amp;quot;fas&amp;quot; &amp;gt;}} Terminal  
{{&amp;lt; icon name=&amp;quot;python&amp;quot; pack=&amp;quot;fab&amp;quot; &amp;gt;}} Python  
{{&amp;lt; icon name=&amp;quot;r-project&amp;quot; pack=&amp;quot;fab&amp;quot; &amp;gt;}} R
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;renders as&lt;/p&gt;
&lt;p&gt;
  &lt;i class=&#34;fas fa-terminal  pr-1 fa-fw&#34;&gt;&lt;/i&gt; Terminal&lt;br&gt;

  &lt;i class=&#34;fab fa-python  pr-1 fa-fw&#34;&gt;&lt;/i&gt; Python&lt;br&gt;

  &lt;i class=&#34;fab fa-r-project  pr-1 fa-fw&#34;&gt;&lt;/i&gt; R&lt;/p&gt;
&lt;h3 id=&#34;did-you-find-this-page-helpful-consider-sharing-it-&#34;&gt;Did you find this page helpful? Consider sharing it üôå&lt;/h3&gt;
</description>
    </item>
    
    <item>
      <title>Display Jupyter Notebooks with Academic</title>
      <link>/post/jupyter/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>/post/jupyter/</guid>
      <description>&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from IPython.core.display import Image
Image(&#39;https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png&#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;./index_1_0.png&#34; alt=&#34;png&#34;&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;print(&amp;quot;Welcome to Academic!&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Welcome to Academic!
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;install-python-and-jupyterlab&#34;&gt;Install Python and JupyterLab&lt;/h2&gt;
&lt;p&gt;
&lt;a href=&#34;https://www.anaconda.com/distribution/#download-section&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Install Anaconda&lt;/a&gt; which includes Python 3 and JupyterLab.&lt;/p&gt;
&lt;p&gt;Alternatively, install JupyterLab with &lt;code&gt;pip3 install jupyterlab&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id=&#34;create-or-upload-a-jupyter-notebook&#34;&gt;Create or upload a Jupyter notebook&lt;/h2&gt;
&lt;p&gt;Run the following commands in your Terminal, substituting &lt;code&gt;&amp;lt;MY-WEBSITE-FOLDER&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;SHORT-POST-TITLE&amp;gt;&lt;/code&gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir -p &amp;lt;MY-WEBSITE-FOLDER&amp;gt;/content/post/&amp;lt;SHORT-POST-TITLE&amp;gt;/
cd &amp;lt;MY-WEBSITE-FOLDER&amp;gt;/content/post/&amp;lt;SHORT-POST-TITLE&amp;gt;/
jupyter lab index.ipynb
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;jupyter&lt;/code&gt; command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.&lt;/p&gt;
&lt;h2 id=&#34;edit-your-post-metadata&#34;&gt;Edit your post metadata&lt;/h2&gt;
&lt;p&gt;The first cell of your Jupter notebook will contain your post metadata (
&lt;a href=&#34;https://sourcethemes.com/academic/docs/front-matter/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;front matter&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;In Jupter, choose &lt;em&gt;Markdown&lt;/em&gt; as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;---
title: My post&#39;s title
date: 2019-09-01

# Put any other Academic metadata here...
---
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Edit the metadata of your post, using the 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;documentation&lt;/a&gt; as a guide to the available options.&lt;/p&gt;
&lt;p&gt;To set a 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#featured-image&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;featured image&lt;/a&gt;, place an image named &lt;code&gt;featured&lt;/code&gt; into your post&amp;rsquo;s folder.&lt;/p&gt;
&lt;p&gt;For other tips, such as using math, see the guide on 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;writing content with Academic&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;convert-notebook-to-markdown&#34;&gt;Convert notebook to Markdown&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;example&#34;&gt;Example&lt;/h2&gt;
&lt;p&gt;This post was created with Jupyter. The orginal files can be found at &lt;a href=&#34;https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter&#34;&gt;https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Slides</title>
      <link>/slides/example/</link>
      <pubDate>Tue, 05 Feb 2019 00:00:00 +0000</pubDate>
      <guid>/slides/example/</guid>
      <description>&lt;h1 id=&#34;create-slides-in-markdown-with-academic&#34;&gt;Create slides in Markdown with Academic&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Academic&lt;/a&gt; | 
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Efficiently write slides in Markdown&lt;/li&gt;
&lt;li&gt;3-in-1: Create, Present, and Publish your slides&lt;/li&gt;
&lt;li&gt;Supports speaker notes&lt;/li&gt;
&lt;li&gt;Mobile friendly slides&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;controls&#34;&gt;Controls&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Next: &lt;code&gt;Right Arrow&lt;/code&gt; or &lt;code&gt;Space&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Previous: &lt;code&gt;Left Arrow&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Start: &lt;code&gt;Home&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Finish: &lt;code&gt;End&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Overview: &lt;code&gt;Esc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Speaker notes: &lt;code&gt;S&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Fullscreen: &lt;code&gt;F&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Zoom: &lt;code&gt;Alt + Click&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://github.com/hakimel/reveal.js#pdf-export&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF Export&lt;/a&gt;: &lt;code&gt;E&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;code-highlighting&#34;&gt;Code Highlighting&lt;/h2&gt;
&lt;p&gt;Inline code: &lt;code&gt;variable&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Code block:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;porridge = &amp;quot;blueberry&amp;quot;
if porridge == &amp;quot;blueberry&amp;quot;:
    print(&amp;quot;Eating...&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;math&#34;&gt;Math&lt;/h2&gt;
&lt;p&gt;In-line math: $x + y = z$&lt;/p&gt;
&lt;p&gt;Block math:&lt;/p&gt;
&lt;p&gt;$$
f\left( x \right) = ;\frac{{2\left( {x + 4} \right)\left( {x - 4} \right)}}{{\left( {x + 4} \right)\left( {x + 1} \right)}}
$$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;fragments&#34;&gt;Fragments&lt;/h2&gt;
&lt;p&gt;Make content appear incrementally&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{{% fragment %}} One {{% /fragment %}}
{{% fragment %}} **Two** {{% /fragment %}}
{{% fragment %}} Three {{% /fragment %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press &lt;code&gt;Space&lt;/code&gt; to play!&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;fragment &#34; &gt;
One
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
&lt;strong&gt;Two&lt;/strong&gt;
&lt;/span&gt;
&lt;span class=&#34;fragment &#34; &gt;
Three
&lt;/span&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;A fragment can accept two optional parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;class&lt;/code&gt;: use a custom style (requires definition in custom CSS)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;weight&lt;/code&gt;: sets the order in which a fragment appears&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;speaker-notes&#34;&gt;Speaker Notes&lt;/h2&gt;
&lt;p&gt;Add speaker notes to your presentation&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{% speaker_note %}}
- Only the speaker can read these notes
- Press `S` key to view
{{% /speaker_note %}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Press the &lt;code&gt;S&lt;/code&gt; key to view the speaker notes!&lt;/p&gt;
&lt;aside class=&#34;notes&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Only the speaker can read these notes&lt;/li&gt;
&lt;li&gt;Press &lt;code&gt;S&lt;/code&gt; key to view&lt;/li&gt;
&lt;/ul&gt;

&lt;/aside&gt;
&lt;hr&gt;
&lt;h2 id=&#34;themes&#34;&gt;Themes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;black: Black background, white text, blue links (default)&lt;/li&gt;
&lt;li&gt;white: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;league: Gray background, white text, blue links&lt;/li&gt;
&lt;li&gt;beige: Beige background, dark text, brown links&lt;/li&gt;
&lt;li&gt;sky: Blue background, thin dark text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;night: Black background, thick white text, orange links&lt;/li&gt;
&lt;li&gt;serif: Cappuccino background, gray text, brown links&lt;/li&gt;
&lt;li&gt;simple: White background, black text, blue links&lt;/li&gt;
&lt;li&gt;solarized: Cream-colored background, dark green text, blue links&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;

&lt;section data-noprocess data-shortcode-slide
  
      
      data-background-image=&#34;/img/boards.jpg&#34;
  &gt;

&lt;h2 id=&#34;custom-slide&#34;&gt;Custom Slide&lt;/h2&gt;
&lt;p&gt;Customize the slide style and background&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-markdown&#34;&gt;{{&amp;lt; slide background-image=&amp;quot;/img/boards.jpg&amp;quot; &amp;gt;}}
{{&amp;lt; slide background-color=&amp;quot;#0000FF&amp;quot; &amp;gt;}}
{{&amp;lt; slide class=&amp;quot;my-style&amp;quot; &amp;gt;}}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h2 id=&#34;custom-css-example&#34;&gt;Custom CSS Example&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s make headers navy colored.&lt;/p&gt;
&lt;p&gt;Create &lt;code&gt;assets/css/reveal_custom.css&lt;/code&gt; with:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-css&#34;&gt;.reveal section h1,
.reveal section h2,
.reveal section h3 {
  color: navy;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;hr&gt;
&lt;h1 id=&#34;questions&#34;&gt;Questions?&lt;/h1&gt;
&lt;p&gt;
&lt;a href=&#34;https://spectrum.chat/academic&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href=&#34;https://sourcethemes.com/academic/docs/managing-content/#create-slides&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Documentation&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Terms</title>
      <link>/terms/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate>
      <guid>/terms/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hello R Markdown</title>
      <link>/post/2015-07-23-r-rmarkdown/</link>
      <pubDate>Thu, 23 Jul 2015 21:13:14 -0500</pubDate>
      <guid>/post/2015-07-23-r-rmarkdown/</guid>
      <description>


&lt;div id=&#34;r-markdown&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;R Markdown&lt;/h1&gt;
&lt;p&gt;This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see &lt;a href=&#34;http://rmarkdown.rstudio.com&#34; class=&#34;uri&#34;&gt;http://rmarkdown.rstudio.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can embed an R code chunk like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(cars)
##      speed           dist       
##  Min.   : 4.0   Min.   :  2.00  
##  1st Qu.:12.0   1st Qu.: 26.00  
##  Median :15.0   Median : 36.00  
##  Mean   :15.4   Mean   : 42.98  
##  3rd Qu.:19.0   3rd Qu.: 56.00  
##  Max.   :25.0   Max.   :120.00
fit &amp;lt;- lm(dist ~ speed, data = cars)
fit
## 
## Call:
## lm(formula = dist ~ speed, data = cars)
## 
## Coefficients:
## (Intercept)        speed  
##     -17.579        3.932&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;including-plots&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Including Plots&lt;/h1&gt;
&lt;p&gt;You can also embed plots. See Figure &lt;a href=&#34;#fig:pie&#34;&gt;1&lt;/a&gt; for example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mar = c(0, 1, 0, 1))
pie(
  c(280, 60, 20),
  c(&amp;#39;Sky&amp;#39;, &amp;#39;Sunny side of pyramid&amp;#39;, &amp;#39;Shady side of pyramid&amp;#39;),
  col = c(&amp;#39;#0292D8&amp;#39;, &amp;#39;#F7EA39&amp;#39;, &amp;#39;#C4B632&amp;#39;),
  init.angle = -50, border = NA
)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:pie&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;/post/2015-07-23-r-rmarkdown_files/figure-html/pie-1.png&#34; alt=&#34;A fancy pie chart.&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: A fancy pie chart.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
